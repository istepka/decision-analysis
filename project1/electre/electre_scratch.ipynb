{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[1. , 1. , 1. , 0. ],\n",
       "         [0. , 1. , 0. , 1. ],\n",
       "         [1. , 1. , 1. , 1. ],\n",
       "         [1. , 1. , 0. , 1. ],\n",
       "         [0.5, 1. , 0. , 0. ],\n",
       "         [1. , 1. , 0. , 1. ],\n",
       "         [1. , 1. , 0. , 1. ],\n",
       "         [1. , 0. , 0. , 0. ]],\n",
       " \n",
       "        [[1. , 1. , 1. , 0. ],\n",
       "         [0. , 1. , 0. , 1. ],\n",
       "         [1. , 1. , 0. , 0. ],\n",
       "         [0. , 0. , 0. , 1. ],\n",
       "         [0. , 0. , 0. , 0. ],\n",
       "         [0. , 0. , 0. , 1. ],\n",
       "         [0. , 1. , 0. , 1. ],\n",
       "         [0. , 0. , 0. , 0. ]]]),\n",
       " array([[[0.        , 0.        , 0.        , 1.        ],\n",
       "         [1.        , 0.        , 1.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        , 0.        ],\n",
       "         [1.        , 1.        , 1.        , 1.        ],\n",
       "         [1.        , 0.        , 1.        , 0.        ],\n",
       "         [1.        , 0.        , 1.        , 0.        ],\n",
       "         [0.        , 1.        , 1.        , 1.        ]],\n",
       " \n",
       "        [[0.75      , 1.        , 0.        , 1.        ],\n",
       "         [1.        , 0.33333333, 1.        , 0.        ],\n",
       "         [0.        , 0.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        , 0.        ],\n",
       "         [1.        , 1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        , 0.        ],\n",
       "         [1.        , 0.66666667, 1.        , 0.        ],\n",
       "         [1.        , 1.        , 1.        , 1.        ]]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concordance_function(difference,indifference,preference,gain):\n",
    "    if gain:\n",
    "        if difference >= -indifference:\n",
    "            return 1\n",
    "        elif difference < -preference:\n",
    "            return 0\n",
    "        else:\n",
    "            return (preference + difference) / (preference-indifference)\n",
    "    else:\n",
    "        if difference <= indifference:\n",
    "            return 1\n",
    "        elif difference > preference:\n",
    "            return 0\n",
    "        else:\n",
    "            return (preference-difference) / (preference-indifference)\n",
    "\n",
    "\n",
    "def calculate_marginal_concordance(alternatives, boundary_profiles, indifference_thresholds, preference_thresholds, gain,concordance_function=concordance_function):\n",
    "    # Calculate marginal concordance for each alternative and boundary profile\n",
    "    # Arguments:\n",
    "    #   alternatives: pandas dataframe with alternatives\n",
    "    #   boundary_profiles: pandas dataframe with boundary profiles\n",
    "    #   indifference_thresholds: list of indifference thresholds for each boundary profile\n",
    "    #   preference_thresholds: list of preference thresholds for each boundary profile\n",
    "    #   gain: list of boolean values indicating whether the criterion is gain or cost\n",
    "    # Returns:\n",
    "    #   marginal_concordance: numpy array with marginal concordance in the shape of (number of criteria, number of alternatives, number of boundary profiles)\n",
    "\n",
    "    marginal_concordance_alt_to_profile = np.zeros((len(boundary_profiles),len(alternatives),len(alternatives.columns),))\n",
    "    marginal_concordance_profile_to_alt = np.zeros((len(boundary_profiles),len(alternatives),len(alternatives.columns),))\n",
    "\n",
    "    for i in range(len(alternatives)):\n",
    "        for j in range(len(boundary_profiles)):\n",
    "            for k in range(len(alternatives.columns)):\n",
    "                difference = alternatives.iloc[i,k] - boundary_profiles.iloc[j,k]\n",
    "                \n",
    "                indifference = indifference_thresholds[j][k]\n",
    "                preference = preference_thresholds[j][k]\n",
    "                marginal_concordance_alt_to_profile[j,i,k] = concordance_function(difference, indifference, preference, gain[k])\n",
    "                marginal_concordance_profile_to_alt[j,i,k] = concordance_function(-difference, indifference, preference, gain[k])\n",
    "\n",
    "    return marginal_concordance_alt_to_profile,marginal_concordance_profile_to_alt\n",
    "\n",
    "def test_marginal_concordance():\n",
    "\n",
    "    \n",
    "    test_alternatives = pd.DataFrame([[90,86,46,30],\n",
    "    [40,90,14,48],\n",
    "    [94,100,40,36],\n",
    "    [78,76,30,50],\n",
    "    [60,60,30,30],\n",
    "    [64,72,12,46],\n",
    "    [62,88,22,48],\n",
    "    [70,30,12,12]]).astype(float)\n",
    "    test_boundary_profiles = pd.DataFrame( [[64,61,32,32],\n",
    "[86,84,43,43]]).astype(float)\n",
    "    test_indifference_thresholds = [[2,2,0,0],[3,2,0,0]]\n",
    "    test_preference_thresholds = [[6,5,2,2],[7,8,2,2]]\n",
    "\n",
    "    test_gains = [True,True,True,True]\n",
    "\n",
    "    marginal_concordance_alt_to_profile, marginal_concordance_profile_to_alt = calculate_marginal_concordance(test_alternatives, test_boundary_profiles, test_indifference_thresholds, test_preference_thresholds, test_gains)\n",
    "\n",
    "    concordance_matrix_alt_to_profile = np.array(\n",
    "        [\n",
    "        [1,1,1,0],\n",
    "        [0,1,0,1],\n",
    "        [1,1,1,1],\n",
    "        [1,1,0,1],\n",
    "        [0.5,1,0,0],\n",
    "        [1,1,0,1],\n",
    "        [1,1,0,1],\n",
    "        [1,0,0,0]\n",
    "        ],\n",
    "    )\n",
    "    concordance_matrix_profile_to_alt = np.array(\n",
    "        [\n",
    "        [0,0,0,1],\n",
    "        [1,0,1,0],\n",
    "        [0,0,0,0],\n",
    "        [0,0,1,0],\n",
    "        [1,1,1,1],\n",
    "        [1,0,1,0],\n",
    "        [1,0,1,0],\n",
    "        [0,1,1,1]\n",
    "        ]\n",
    "    )\n",
    "    assert np.allclose(marginal_concordance_alt_to_profile[0], concordance_matrix_alt_to_profile, atol=0.01)\n",
    "    assert np.allclose(marginal_concordance_profile_to_alt[0], concordance_matrix_profile_to_alt, atol=0.01)\n",
    "\n",
    "    return marginal_concordance_alt_to_profile, marginal_concordance_profile_to_alt\n",
    "\n",
    "test_marginal_concordance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.        , 0.        , 0.        , 0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.        , 0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.07692308, 0.        , 0.        , 0.        ],\n",
       "         [1.        , 0.94117647, 0.        , 0.        ],\n",
       "         [1.        , 0.23529412, 0.        , 0.        ],\n",
       "         [1.        , 0.        , 0.        , 0.        ],\n",
       "         [0.69230769, 1.        , 0.        , 0.        ]]]),\n",
       " array([[[1.        , 1.        , 0.        , 0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        ],\n",
       "         [1.        , 1.        , 0.        , 0.        ],\n",
       "         [0.57142857, 0.52631579, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.31578947, 0.        , 0.        ],\n",
       "         [0.        , 1.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.07692308, 0.47058824, 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , 0.        ]]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discordance_function(difference, veto, preference, gain):\n",
    "    if gain:\n",
    "        if difference <= -veto:\n",
    "            return 1\n",
    "        elif difference >= -preference:\n",
    "            return 0\n",
    "        else :\n",
    "            return (-difference - preference) / (veto-preference)\n",
    "    else:\n",
    "        if difference >= veto:\n",
    "            return 1\n",
    "        elif difference <= preference:\n",
    "            return 0\n",
    "        else:\n",
    "            return (veto - difference) / (veto-preference)\n",
    "\n",
    "def calculate_marginal_discordance(alternatives,boundary_profiles,preference_thresholds,veto_thresholds,gain,discordance_function=discordance_function):\n",
    "\n",
    "    marginal_discordance_alt_to_profile = np.zeros((len(boundary_profiles),len(alternatives),len(alternatives.columns),))\n",
    "    marginal_discordance_profile_to_alt = np.zeros((len(boundary_profiles),len(alternatives),len(alternatives.columns),))\n",
    "\n",
    "    for i in range(len(alternatives)):\n",
    "        for j in range(len(boundary_profiles)):\n",
    "            for k in range(len(alternatives.columns)):\n",
    "                difference = alternatives.iloc[i,k] - boundary_profiles.iloc[j,k]\n",
    "                \n",
    "                veto = veto_thresholds[j][k]\n",
    "                preference = preference_thresholds[j][k]\n",
    "                marginal_discordance_alt_to_profile[j,i,k] = discordance_function(difference, veto, preference, gain[k])\n",
    "                marginal_discordance_profile_to_alt[j,i,k] = discordance_function(-difference, veto, preference, gain[k])\n",
    "\n",
    "    return marginal_discordance_alt_to_profile,marginal_discordance_profile_to_alt\n",
    "\n",
    "def test_marginal_discordance():\n",
    "\n",
    "    test_alternatives = pd.DataFrame([[90,86,46,30],\n",
    "    [40,90,14,48],\n",
    "    [94,100,40,36],\n",
    "    [78,76,30,50],\n",
    "    [60,60,30,30],\n",
    "    [64,72,12,46],\n",
    "    [62,88,22,48],\n",
    "    [70,30,12,12]]).astype(float)\n",
    "    test_boundary_profiles = pd.DataFrame( [[64,61,32,32],\n",
    "[86,84,43,43]]).astype(float)\n",
    "    test_veto_thresholds = [[20,24,np.inf,np.inf],[20,25,np.inf,np.inf]]\n",
    "    test_preference_thresholds = [[6,5,2,2],[7,8,2,2]]\n",
    "\n",
    "    test_gains = [True,True,True,True]\n",
    "\n",
    "    discordance_alt_to_profile = np.array([\n",
    "        [0,0,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0,0,0,0],\n",
    "        [0.07,0,0,0],\n",
    "        [1,0.94,0,0],\n",
    "        [1,0.23,0,0],\n",
    "        [1,0,0,0],\n",
    "        [0.69,1,0,0]\n",
    "    ])\n",
    "    discordance_profile_to_alt = np.array([\n",
    "        [1,1,0,0],\n",
    "        [0,1,0,0],\n",
    "        [1,1,0,0],\n",
    "        [0.57,0.52,0,0],\n",
    "        [0,0,0,0],\n",
    "        [0,0.31,0,0],\n",
    "        [0,1,0,0],\n",
    "        [0,0,0,0]\n",
    "    ])\n",
    "\n",
    "    marginal_discordance_alt_to_profile, marginal_discordance_profile_to_alt = calculate_marginal_discordance(test_alternatives, test_boundary_profiles, test_preference_thresholds, test_veto_thresholds,test_gains)\n",
    "\n",
    "    assert np.allclose(marginal_discordance_alt_to_profile[1], discordance_alt_to_profile, atol=0.01)\n",
    "    assert np.allclose(marginal_discordance_profile_to_alt[0], discordance_profile_to_alt, atol=0.01)\n",
    "\n",
    "    return marginal_discordance_alt_to_profile, marginal_discordance_profile_to_alt\n",
    "    \n",
    "test_marginal_discordance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.95, 0.95],\n",
       "        [0.35, 0.35],\n",
       "        [1.  , 0.7 ],\n",
       "        [0.75, 0.05],\n",
       "        [0.5 , 0.  ],\n",
       "        [0.75, 0.05],\n",
       "        [0.75, 0.35],\n",
       "        [0.4 , 0.  ]]),\n",
       " array([[0.05, 0.65],\n",
       "        [0.65, 0.75],\n",
       "        [0.  , 0.3 ],\n",
       "        [0.25, 0.95],\n",
       "        [1.  , 1.  ],\n",
       "        [0.65, 0.95],\n",
       "        [0.65, 0.85],\n",
       "        [0.6 , 1.  ]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_comprehensive_concordance(concordance_matrix_alt_to_profile, concordance_matrix_profile_to_alt,weights):\n",
    "\n",
    "    # weighted average of concordances for each alternative\n",
    "\n",
    "    comprehensive_concordance_alt_to_profile = np.average(concordance_matrix_alt_to_profile, axis=2, weights=weights)\n",
    "    comprehensive_concordance_profile_to_alt = np.average(concordance_matrix_profile_to_alt, axis=2, weights=weights)\n",
    "\n",
    "    return comprehensive_concordance_alt_to_profile.T, comprehensive_concordance_profile_to_alt.T\n",
    "\n",
    "def test_comprehensive_concordance():\n",
    "\n",
    "    concordance_matrix_alt_to_profile, concordance_matrix_profile_to_alt = test_marginal_concordance()\n",
    "\n",
    "    weights = [0.4,0.3,0.25,0.05]\n",
    "\n",
    "    comprehensive_concordance_alt_to_profile, comprehensive_concordance_profile_to_alt = calculate_comprehensive_concordance(concordance_matrix_alt_to_profile, concordance_matrix_profile_to_alt,weights)\n",
    "    return comprehensive_concordance_alt_to_profile, comprehensive_concordance_profile_to_alt\n",
    "\n",
    "test_comprehensive_concordance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.95      , 0.        ],\n",
       "        [0.95      , 0.65      ]],\n",
       "\n",
       "       [[0.        , 0.        ],\n",
       "        [0.        , 0.75      ]],\n",
       "\n",
       "       [[1.        , 0.        ],\n",
       "        [0.7       , 0.22689076]],\n",
       "\n",
       "       [[0.75      , 0.09022556],\n",
       "        [0.048583  , 0.95      ]],\n",
       "\n",
       "       [[0.5       , 1.        ],\n",
       "        [0.        , 1.        ]],\n",
       "\n",
       "       [[0.75      , 0.65      ],\n",
       "        [0.        , 0.95      ]],\n",
       "\n",
       "       [[0.75      , 0.        ],\n",
       "        [0.        , 0.85      ]],\n",
       "\n",
       "       [[0.        , 0.6       ],\n",
       "        [0.        , 1.        ]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_outranking_credibility(comprehensive_concordance,marginal_discordance):\n",
    "    # Returns array of outranking credibility for each alternative\n",
    "    # outranking[alternative][boundary profile][0] = outranking credibility of alternative to boundary profile\n",
    "    # outranking[alternative][boundary profile][1] = outranking credibility of boundary profile to alternative\n",
    "    outrankings = np.zeros((len(comprehensive_concordance[0]),len(comprehensive_concordance[0][0]),2))\n",
    "    for i in range(len(comprehensive_concordance[0])): # numver of alternatives\n",
    "        for j in range(len(comprehensive_concordance[0][0])): # number of boundary profiles\n",
    "            outranking = [comprehensive_concordance[0][i][j], comprehensive_concordance[1][i][j]]\n",
    "            for k in range(len(marginal_discordance[0])): # number of criteria\n",
    "                \n",
    "                if comprehensive_concordance[0][i][j] < marginal_discordance[0][j][i][k]: # alt_to_profile\n",
    "                    outranking[0] *= (1-marginal_discordance[0][j][i][k])/(1-comprehensive_concordance[0][i][j])\n",
    "                if comprehensive_concordance[1][i][j] < marginal_discordance[1][j][i][k]: # profile_to_alt\n",
    "                    outranking[1] *= (1-marginal_discordance[1][j][i][k])/(1-comprehensive_concordance[1][i][j])\n",
    "            outrankings[i][j] = outranking\n",
    "    \n",
    "    return outrankings\n",
    "\n",
    "def test_outranking_credibility():\n",
    "\n",
    "    comprehensive_concordance = test_comprehensive_concordance()\n",
    "    marginal_discordance = test_marginal_discordance()\n",
    "\n",
    "    outrankings = calculate_outranking_credibility(comprehensive_concordance,marginal_discordance)\n",
    "    test_outrankings = np.array([[0.95,0],[0.95,0.65]])\n",
    "    assert np.allclose(outrankings[0], test_outrankings, atol=0.01)\n",
    "    return outrankings\n",
    "test_outranking_credibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [nan]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [nan]]\n",
      "[[ 0.]\n",
      " [-1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "def preference_aggregation(aPb,bPa):\n",
    "    if aPb and not bPa:\n",
    "        return 1 # a is preferred to b\n",
    "    if not aPb and bPa:\n",
    "        return -1 # b is preferred to a\n",
    "    if aPb and bPa: \n",
    "        return 0 # indifferent\n",
    "    if not aPb and not bPa:\n",
    "        return None # incomparable\n",
    "\n",
    "def transform_outranking_to_preference(outrankings,credibility_threshold=0.65):\n",
    "\n",
    "    outranking_preference = np.zeros((len(outrankings),len(outrankings[0])))\n",
    "    for i in range(len(outrankings)): # alternatives\n",
    "        for j in range(len(outrankings[0])): # boundary profiles\n",
    "            outranking_preference[i][j] = preference_aggregation(outrankings[i][j][0] >= credibility_threshold, outrankings[i][j][1] >= credibility_threshold)\n",
    "    return outranking_preference\n",
    "\n",
    "def test_transform_outranking_to_preference():\n",
    "    outrankings = test_outranking_credibility()\n",
    "    outranking_preference = transform_outranking_to_preference(outrankings)\n",
    "    assert np.allclose(outranking_preference[:,0:1].flatten(), [[1,np.nan,1,1,-1,0,1,np.nan]], equal_nan=True)\n",
    "    return outranking_preference\n",
    "\n",
    "preference = test_transform_outranking_to_preference()\n",
    "print(preference[:,0:1])\n",
    "print(preference[:,1:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 1, 3, 2, 1, 2, 2, 1]), array([3., 2., 3., 2., 1., 2., 2., 2.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_assignment(preference_matrix,num_classes, pessimistic=True):\n",
    "    if pessimistic:\n",
    "        # fill array of size len(preference_matrix) with max value of 2\n",
    "        classes = np.full(len(preference_matrix),num_classes)\n",
    "\n",
    "    else:\n",
    "        classes = np.ones(len(preference_matrix))\n",
    "\n",
    "\n",
    "    for j,a in enumerate(preference_matrix):\n",
    "        if pessimistic:\n",
    "            for i in range(len(a)-1,-1,-1):\n",
    "                \n",
    "                if a[i] >=0:\n",
    "                    break\n",
    "                classes[j]-=1\n",
    "            \n",
    "        else:\n",
    "            for i in range(len(a)):\n",
    "                if a[i] == -1:\n",
    "                    break\n",
    "                classes[j]+=1\n",
    "                \n",
    "    return classes\n",
    "\n",
    "def test_class_assignment():\n",
    "\n",
    "    preference = test_transform_outranking_to_preference()\n",
    "    classes_pess = class_assignment(preference,3,True)\n",
    "    classes_opt = class_assignment(preference,3,False)\n",
    "    assert np.allclose(classes_pess, [3,1,3,2,1,2,2,1])\n",
    "    assert np.allclose(classes_opt, [3,2,3,2,1,2,2,2])\n",
    "    return classes_pess, classes_opt\n",
    "\n",
    "test_class_assignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 3, 2, 1, 2, 2, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def electre_tri_b(alternatives,boundary_profiles,criteria_is_gain,indifference_thresholds,preference_thresholds,veto_thresholds,weights,pessimistic=True):\n",
    "    # Returns array of classes for each alternative\n",
    "\n",
    "    # Calculate concordance and discordance matrices\n",
    "    concordance_matrix_alt_to_profile, concordance_matrix_profile_to_alt = calculate_marginal_concordance(alternatives,boundary_profiles,indifference_thresholds,preference_thresholds,criteria_is_gain)\n",
    "    discordance_matrix_alt_to_profile, discordance_matrix_profile_to_alt = calculate_marginal_discordance(alternatives,boundary_profiles,preference_thresholds,veto_thresholds,criteria_is_gain)\n",
    "\n",
    "    # Calculate comprehensive concordance\n",
    "    comprehensive_concordance = calculate_comprehensive_concordance(concordance_matrix_alt_to_profile,concordance_matrix_profile_to_alt,weights)\n",
    "\n",
    "    # Calculate outranking credibility\n",
    "    outrankings = calculate_outranking_credibility(comprehensive_concordance,[discordance_matrix_alt_to_profile,discordance_matrix_profile_to_alt])\n",
    "\n",
    "    # Transform outranking credibility to preference\n",
    "    outranking_preference = transform_outranking_to_preference(outrankings)\n",
    "\n",
    "    # Assign classes\n",
    "    classes = class_assignment(outranking_preference,len(boundary_profiles)+1,pessimistic)\n",
    "\n",
    "    \n",
    "    return classes\n",
    "\n",
    "def test_electre_tri_b():\n",
    "    \n",
    "    test_alternatives = pd.DataFrame([[70,98,78,76],\n",
    "    [44,51,23,46],\n",
    "    [94,100,43,36],\n",
    "    [78,76,30,50],\n",
    "    [60,60,30,30],\n",
    "    [64,72,12,46],\n",
    "    [62,88,22,48],\n",
    "    [70,30,12,12]]).astype(float)\n",
    "    test_boundary_profiles = pd.DataFrame( [[64,61,32,32],\n",
    "[86,84,43,43]]).astype(float)\n",
    "    test_veto_thresholds = [[20,24,np.inf,np.inf],[20,25,np.inf,np.inf]]\n",
    "    test_preference_thresholds = [[6,5,2,2],[7,8,2,2]]\n",
    "    test_indifference_thresholds = [[2,2,0,0],[3,2,0,0]]\n",
    "    test_gains = [True,True,True,True]\n",
    "    test_weights = [0.4,0.3,0.25,0.05]\n",
    "\n",
    "    classes = electre_tri_b(test_alternatives,test_boundary_profiles,test_gains,test_indifference_thresholds,test_preference_thresholds,test_veto_thresholds,test_weights)\n",
    "    assert np.allclose(classes, [3,1,3,2,1,2,2,1])\n",
    "    return classes\n",
    "\n",
    "test_electre_tri_b() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hparams \n",
    "\n",
    "Must watch\n",
    "Good movie\n",
    "Meh\n",
    "Maybe\n",
    "Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_profiles = pd.DataFrame([\n",
    "    [100,100,100,100,100,100,100],\n",
    "    [100,100,100,100,100,100,100],\n",
    "    [100,100,100,100,100,100,100],\n",
    "    [100,100,100,100,100,100,100],\n",
    "])\n",
    "# I feel indifferent when the difference is X\n",
    "INDIFFERENCE_THRESHOLDS = [\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "]\n",
    "# I feel preference when the difference is X\n",
    "PREFERENCE_THRESHOLDS = [\n",
    "    [5, 5, 5, 5, 5, 5, 5],\n",
    "    [5, 5, 5, 5, 5, 5, 5],\n",
    "    [5, 5, 5, 5, 5, 5, 5],\n",
    "    [5, 5, 5, 5, 5, 5, 5],\n",
    "]\n",
    "# A is always better than B if the difference is X and there is no question about that\n",
    "VETO_THRESHOLDS = [\n",
    "    [10, 10, 10, 10, 10, 10, 10],\n",
    "    [10, 10, 10, 10, 10, 10, 10],\n",
    "    [10, 10, 10, 10, 10, 10, 10],\n",
    "    [10, 10, 10, 10, 10, 10, 10],\n",
    "]\n",
    "gain = [True, True, True, True, True, True, True]\n",
    "\n",
    "WEIGHTS = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "boundary_profiles.columns = ['Acting','Plot','Pictures','Music','Sentiment', 'Critics Score', 'Oscars Won']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOUNDARY PROFILE 0\n",
      "\n",
      "               Acting  Plot  Pictures  Music  Sentiment  Critics Score  \\\n",
      "threshold                                                               \n",
      "indifference       1     1         1      1          1              1   \n",
      "preference         5     5         5      5          5              5   \n",
      "veto              10    10        10     10         10             10   \n",
      "\n",
      "              Oscars Won  \n",
      "threshold                 \n",
      "indifference           1  \n",
      "preference             5  \n",
      "veto                  10  \n",
      "BOUNDARY PROFILE 1\n",
      "\n",
      "               Acting  Plot  Pictures  Music  Sentiment  Critics Score  \\\n",
      "threshold                                                               \n",
      "indifference       1     1         1      1          1              1   \n",
      "preference         5     5         5      5          5              5   \n",
      "veto              10    10        10     10         10             10   \n",
      "\n",
      "              Oscars Won  \n",
      "threshold                 \n",
      "indifference           1  \n",
      "preference             5  \n",
      "veto                  10  \n",
      "BOUNDARY PROFILE 2\n",
      "\n",
      "               Acting  Plot  Pictures  Music  Sentiment  Critics Score  \\\n",
      "threshold                                                               \n",
      "indifference       1     1         1      1          1              1   \n",
      "preference         5     5         5      5          5              5   \n",
      "veto              10    10        10     10         10             10   \n",
      "\n",
      "              Oscars Won  \n",
      "threshold                 \n",
      "indifference           1  \n",
      "preference             5  \n",
      "veto                  10  \n"
     ]
    }
   ],
   "source": [
    "b0 = pd.DataFrame([INDIFFERENCE_THRESHOLDS[0],PREFERENCE_THRESHOLDS[0],VETO_THRESHOLDS[0]],columns=boundary_profiles.columns)\n",
    "b0[\"threshold\"] = [\"indifference\",\"preference\",\"veto\"]\n",
    "b0 = b0.set_index(\"threshold\")\n",
    "\n",
    "b1 = pd.DataFrame([INDIFFERENCE_THRESHOLDS[1],PREFERENCE_THRESHOLDS[1],VETO_THRESHOLDS[1]],columns=boundary_profiles.columns)\n",
    "b1[\"threshold\"] = [\"indifference\",\"preference\",\"veto\"]\n",
    "b1 = b1.set_index(\"threshold\")\n",
    "\n",
    "b2 = pd.DataFrame([INDIFFERENCE_THRESHOLDS[2],PREFERENCE_THRESHOLDS[2],VETO_THRESHOLDS[2]],columns=boundary_profiles.columns)\n",
    "b2[\"threshold\"] = [\"indifference\",\"preference\",\"veto\"]\n",
    "b2 = b2.set_index(\"threshold\")\n",
    "\n",
    "print(\"BOUNDARY PROFILE 0\\n\\n\",b0)\n",
    "print(\"BOUNDARY PROFILE 1\\n\\n\",b1)\n",
    "print(\"BOUNDARY PROFILE 2\\n\\n\",b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_alternatives = pd.DataFrame([[70,98,78,76],\n",
    "[44,51,23,46],\n",
    "[94,100,43,36],\n",
    "[78,76,30,50],\n",
    "[60,60,30,30],\n",
    "[64,72,12,46],\n",
    "[62,88,22,48],\n",
    "[70,30,12,12]]).astype(float)\n",
    "test_boundary_profiles = pd.DataFrame([[64,61,32,32], [86,84,43,43]]).astype(float)\n",
    "test_veto_thresholds = [[20,24,np.inf,np.inf],[20,25,np.inf,np.inf]]\n",
    "test_preference_thresholds = [[6,5,2,2],[7,8,2,2]]\n",
    "test_indifference_thresholds = [[2,2,0,0],[3,2,0,0]]\n",
    "test_gains = [True,True,True,True]\n",
    "test_weights = [0.4,0.3,0.25,0.05]\n",
    "\n",
    "classes = electre_tri_b(test_alternatives,test_boundary_profiles,test_gains,test_indifference_thresholds,test_preference_thresholds,test_veto_thresholds,test_weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defaultenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
